{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import email\n",
    "import pickle\n",
    "\n",
    "import os; \n",
    "from os import listdir\n",
    "from os.path import join, isdir\n",
    "\n",
    "import pandas as pd\n",
    "import swifter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "path = \"/media/becode/3D_House/Enron_CSV/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mails = pd.read_csv(join(path, \"all_mails.csv\"), index_col=0)\n",
    "employee = pd.read_csv(join(path, \"enron_employees.csv\"), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mails_lookup = {\n",
    "    employ: employee.loc[idx, \"Mails\"]\n",
    "    for idx, employ in enumerate(list(employee[\"Employ\"]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "employ = \"allen-p\"\n",
    "df = all_mails[all_mails[\"X-Origin\"]== employ]\n",
    "df = df[df[\"From\"].apply(lambda x:x in (mails_lookup[employ]))]\n",
    "df = df[[\"Content\", \"Date\", \"From\", \"To\", \"Subject\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def get_lemma(word):\n",
    "    lemma = wordnet.morphy(word)\n",
    "    if lemma is None: return word\n",
    "    else: return lemma\n",
    "\n",
    "import en_core_web_lg\n",
    "eng = en_core_web_lg.load()\n",
    "vectorize = lambda x: [eng.vocab[w].vector for w in x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce all mails to sent only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 150 allen-p took 4.33 seconds.\n",
      "2 / 150 arnold-j took 7.88 seconds.\n",
      "3 / 150 arora-h took 0.37 seconds.\n",
      "4 / 150 badeer-r took 0.47 seconds.\n",
      "5 / 150 bailey-s took 0.59 seconds.\n",
      "6 / 150 bass-e took 8.61 seconds.\n",
      "7 / 150 baughman-d took 0.44 seconds.\n",
      "8 / 150 beck-s took 9.76 seconds.\n",
      "9 / 150 benson-r took 0.21 seconds.\n",
      "10 / 150 blair-l took 3.83 seconds.\n",
      "11 / 150 brawner-s took 1.19 seconds.\n",
      "12 / 150 buy-r took 1.99 seconds.\n",
      "13 / 150 campbell-l took 3.48 seconds.\n",
      "14 / 150 carson-m took 0.9 seconds.\n",
      "15 / 150 cash-m took 5.62 seconds.\n",
      "16 / 150 causholli-m took 1.41 seconds.\n",
      "17 / 150 corman-s took 2.04 seconds.\n",
      "18 / 150 crandell-s took 0.81 seconds.\n",
      "19 / 150 cuilla-m took 0.67 seconds.\n",
      "20 / 150 dasovich-j took 30.18 seconds.\n",
      "21 / 150 davis-d took 1.42 seconds.\n",
      "22 / 150 dean-c took 0.13 seconds.\n",
      "23 / 150 delainey-d took 6.74 seconds.\n",
      "24 / 150 derrick-j took 2.95 seconds.\n",
      "25 / 150 dickson-s took 0.62 seconds.\n",
      "26 / 150 donoho-l took 0.65 seconds.\n",
      "27 / 150 donohoe-t took 0.17 seconds.\n",
      "28 / 150 dorland-c took 3.11 seconds.\n",
      "29 / 150 ermis-f took 0.14 seconds.\n",
      "30 / 150 farmer-d took 5.64 seconds.\n",
      "31 / 150 fischer-m took 0.29 seconds.\n",
      "32 / 150 forney-j took 1.35 seconds.\n",
      "33 / 150 fossum-d took 9.47 seconds.\n",
      "34 / 150 gang-l took 0.3 seconds.\n",
      "35 / 150 gay-r took 1.36 seconds.\n",
      "36 / 150 geaccone-t took 1.97 seconds.\n",
      "37 / 150 germany-c took 14.03 seconds.\n",
      "38 / 150 gilbertsmith-d took 0.28 seconds.\n",
      "39 / 150 giron-d took 7.08 seconds.\n",
      "40 / 150 griffith-j took 0.65 seconds.\n",
      "41 / 150 grigsby-m took 1.68 seconds.\n",
      "42 / 150 guzman-m took 0.87 seconds.\n",
      "43 / 150 haedicke-m took 4.31 seconds.\n",
      "44 / 150 hain-m took 5.24 seconds.\n",
      "45 / 150 harris-s took 0.06 seconds.\n",
      "46 / 150 hayslett-r took 1.99 seconds.\n",
      "47 / 150 heard-m took 2.46 seconds.\n",
      "48 / 150 hendrickson-s took 0.29 seconds.\n",
      "49 / 150 hernandez-j took 3.94 seconds.\n",
      "50 / 150 hodge-j took 0.22 seconds.\n",
      "51 / 150 holst-k took 0.17 seconds.\n",
      "52 / 150 horton-s took 1.69 seconds.\n",
      "53 / 150 hyatt-k took 1.14 seconds.\n",
      "54 / 150 hyvl-d took 2.8 seconds.\n",
      "55 / 150 jones-t took 16.16 seconds.\n",
      "56 / 150 kaminski-v took 41.49 seconds.\n",
      "57 / 150 kean-s took 25.41 seconds.\n",
      "58 / 150 keavey-p took 0.46 seconds.\n",
      "59 / 150 keiser-k took 0.89 seconds.\n",
      "60 / 150 king-j took 0.13 seconds.\n",
      "61 / 150 kitchen-l took 3.49 seconds.\n",
      "62 / 150 kuykendall-t took 1.72 seconds.\n",
      "63 / 150 lavorato-j took 3.61 seconds.\n",
      "64 / 150 lay-k took 0.12 seconds.\n",
      "65 / 150 lenhart-m took 8.68 seconds.\n",
      "66 / 150 lewis-a took 0.32 seconds.\n",
      "67 / 150 linder-e took 0.07 seconds.\n",
      "68 / 150 lokay-m took 0.06 seconds.\n",
      "69 / 150 lokey-t took 0.57 seconds.\n",
      "70 / 150 love-p took 6.07 seconds.\n",
      "71 / 150 lucci-p took 0.86 seconds.\n",
      "72 / 150 maggi-m took 1.6 seconds.\n",
      "73 / 150 mann-k took 33.41 seconds.\n",
      "74 / 150 martin-t took 0.08 seconds.\n",
      "75 / 150 may-l took 0.43 seconds.\n",
      "76 / 150 mccarty-d took 0.69 seconds.\n",
      "77 / 150 mcconnell-m took 5.41 seconds.\n",
      "78 / 150 mckay-b took 0.07 seconds.\n",
      "79 / 150 mckay-j took 0.9 seconds.\n",
      "80 / 150 mclaughlin-e took 1.85 seconds.\n",
      "81 / 150 merriss-s took 0.06 seconds.\n",
      "82 / 150 meyers-a took 0.23 seconds.\n",
      "83 / 150 mims-thurston-p took 1.28 seconds.\n",
      "84 / 150 motley-m took 0.08 seconds.\n",
      "85 / 150 neal-s took 3.73 seconds.\n",
      "86 / 150 nemec-g took 7.24 seconds.\n",
      "87 / 150 panus-s took 0.56 seconds.\n",
      "88 / 150 parks-j took 1.73 seconds.\n",
      "89 / 150 pereira-s took 1.12 seconds.\n",
      "90 / 150 perlingiere-d took 6.32 seconds.\n",
      "91 / 150 phanis-s took 0.08 seconds.\n",
      "92 / 150 pimenov-v took 0.4 seconds.\n",
      "93 / 150 platter-p took 0.58 seconds.\n",
      "94 / 150 presto-k took 2.84 seconds.\n",
      "95 / 150 quenet-j took 0.32 seconds.\n",
      "96 / 150 quigley-d took 1.52 seconds.\n",
      "97 / 150 rapp-b took 0.34 seconds.\n",
      "98 / 150 reitmeyer-j took 0.21 seconds.\n",
      "99 / 150 richey-c took 1.2 seconds.\n",
      "100 / 150 ring-a took 0.89 seconds.\n",
      "101 / 150 ring-r took 0.06 seconds.\n",
      "102 / 150 rodrique-r took 2.49 seconds.\n",
      "103 / 150 rogers-b took 2.87 seconds.\n",
      "104 / 150 ruscitti-k took 1.11 seconds.\n",
      "105 / 150 sager-e took 5.66 seconds.\n",
      "106 / 150 saibi-e took 0.17 seconds.\n",
      "107 / 150 salisbury-h took 0.46 seconds.\n",
      "108 / 150 sanchez-m took 0.41 seconds.\n",
      "109 / 150 sanders-r took 10.28 seconds.\n",
      "110 / 150 scholtes-d took 0.81 seconds.\n",
      "111 / 150 schoolcraft-d took 2.64 seconds.\n",
      "112 / 150 schwieger-j took 0.63 seconds.\n",
      "113 / 150 scott-s took 1.77 seconds.\n",
      "114 / 150 semperger-c took 0.81 seconds.\n",
      "115 / 150 shackleton-s took 19.39 seconds.\n",
      "116 / 150 shankman-j took 6.76 seconds.\n",
      "117 / 150 shapiro-r took 1.13 seconds.\n",
      "118 / 150 shively-h took 2.18 seconds.\n",
      "119 / 150 skilling-j took 0.33 seconds.\n",
      "120 / 150 slinger-r took 0.15 seconds.\n",
      "121 / 150 smith-m took 0.06 seconds.\n",
      "122 / 150 solberg-g took 0.18 seconds.\n",
      "123 / 150 south-s took 0.15 seconds.\n",
      "124 / 150 staab-t took 0.4 seconds.\n",
      "125 / 150 stclair-c took 5.01 seconds.\n",
      "126 / 150 steffes-j took 5.66 seconds.\n",
      "127 / 150 stepenovitch-j took 0.3 seconds.\n",
      "128 / 150 stokley-c took 1.62 seconds.\n",
      "129 / 150 storey-g took 0.56 seconds.\n",
      "130 / 150 sturm-f took 0.82 seconds.\n",
      "131 / 150 swerzbin-m took 0.29 seconds.\n",
      "132 / 150 symes-k took 6.25 seconds.\n",
      "133 / 150 taylor-m took 0.07 seconds.\n",
      "134 / 150 tholt-j took 1.96 seconds.\n",
      "135 / 150 thomas-p took 0.6 seconds.\n",
      "136 / 150 townsend-j took 0.39 seconds.\n",
      "137 / 150 tycholiz-b took 1.25 seconds.\n",
      "138 / 150 ward-k took 3.21 seconds.\n",
      "139 / 150 watson-k took 3.08 seconds.\n",
      "140 / 150 weldon-c took 1.43 seconds.\n",
      "141 / 150 whalley-g took 0.56 seconds.\n",
      "142 / 150 whalley-l took 0.46 seconds.\n",
      "143 / 150 white-s took 1.87 seconds.\n",
      "144 / 150 whitt-m took 1.24 seconds.\n",
      "145 / 150 williams-j took 0.64 seconds.\n",
      "146 / 150 williams-w3 took 0.06 seconds.\n",
      "147 / 150 wolfe-j took 0.43 seconds.\n",
      "148 / 150 ybarbo-p took 0.66 seconds.\n",
      "149 / 150 zipper-a took 0.72 seconds.\n",
      "150 / 150 zufferli-j took 1.04 seconds.\n",
      "Total time taken: 7.609 minutes.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>Date</th>\n",
       "      <th>From</th>\n",
       "      <th>To</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>VecSum</th>\n",
       "      <th>Origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>254576</th>\n",
       "      <td>---------------------- Forwarded by Phillip K ...</td>\n",
       "      <td>2000-09-01 06:08:00</td>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>mike.grigsby@enron.com, frank.ermis@enron.com</td>\n",
       "      <td>FYI</td>\n",
       "      <td>[forward, phillip, allen, enron, north, americ...</td>\n",
       "      <td>7.766356</td>\n",
       "      <td>allen-p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254452</th>\n",
       "      <td>Naomi,\\n\\nThe two analysts that I have had con...</td>\n",
       "      <td>1999-12-10 07:00:00</td>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>naomi.johnston@enron.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[naomi, analyst, contact, lenhart, vishal, rep...</td>\n",
       "      <td>-14.676489</td>\n",
       "      <td>allen-p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254553</th>\n",
       "      <td>---------------------- Forwarded by Phillip K ...</td>\n",
       "      <td>2000-02-11 04:31:00</td>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>keith.holst@enron.com</td>\n",
       "      <td>RE: W basis quotes</td>\n",
       "      <td>[forward, phillip, allen, george, rahal, georg...</td>\n",
       "      <td>61.238914</td>\n",
       "      <td>allen-p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254418</th>\n",
       "      <td>---------------------- Forwarded by Phillip K ...</td>\n",
       "      <td>2000-02-11 07:39:00</td>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>mike.grigsby@enron.com</td>\n",
       "      <td>Western Strategy Briefing</td>\n",
       "      <td>[forward, phillip, allen, heizenrader, james, ...</td>\n",
       "      <td>-8.750636</td>\n",
       "      <td>allen-p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255431</th>\n",
       "      <td>Let me know when you get the quotes from Pauli...</td>\n",
       "      <td>2001-05-11 11:26:00</td>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>jsmith@austintx.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[quote, pauline, expect, something, range, wou...</td>\n",
       "      <td>16.326239</td>\n",
       "      <td>allen-p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48625</th>\n",
       "      <td>Can you re-activate the Alberta Power Pool Acc...</td>\n",
       "      <td>2001-08-08 10:10:42</td>\n",
       "      <td>john.zufferli@enron.com</td>\n",
       "      <td>help@enrononline.com</td>\n",
       "      <td>Power Pool of Alberta EnronOnline Access</td>\n",
       "      <td>[activate, alberta, power, access, enrononline...</td>\n",
       "      <td>177.460449</td>\n",
       "      <td>zufferli-j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48443</th>\n",
       "      <td>\\n\\n-----Original Message-----\\nFrom: Lalani, ...</td>\n",
       "      <td>2001-08-08 12:39:36</td>\n",
       "      <td>john.zufferli@enron.com</td>\n",
       "      <td>cooper.richey@enron.com</td>\n",
       "      <td>FW: lavo_may_10 (slides 13-16)-revised (Aug 7,...</td>\n",
       "      <td>[original, message, lalani, tuesday, august, z...</td>\n",
       "      <td>12.110354</td>\n",
       "      <td>zufferli-j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48522</th>\n",
       "      <td>Enron Canada Power Corp acknowledges the chang...</td>\n",
       "      <td>2002-01-09 07:30:16</td>\n",
       "      <td>john.zufferli@enron.com</td>\n",
       "      <td>carol.moline@powerpool.ab.ca</td>\n",
       "      <td>Chevron Contract</td>\n",
       "      <td>[enron, canada, power, acknowledge, change, as...</td>\n",
       "      <td>43.984802</td>\n",
       "      <td>zufferli-j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48586</th>\n",
       "      <td>Nella here is a list of products that we would...</td>\n",
       "      <td>2002-01-09 09:46:43</td>\n",
       "      <td>john.zufferli@enron.com</td>\n",
       "      <td>nella.cappelletto@enron.com</td>\n",
       "      <td>Products</td>\n",
       "      <td>[nella, product, would, launch, netco, assume,...</td>\n",
       "      <td>-2.680151</td>\n",
       "      <td>zufferli-j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48559</th>\n",
       "      <td>Here is a list of products and counterparties\\...</td>\n",
       "      <td>2002-01-09 10:38:40</td>\n",
       "      <td>john.zufferli@enron.com</td>\n",
       "      <td>nella.cappelletto@enron.com</td>\n",
       "      <td>RE: Products</td>\n",
       "      <td>[product, counterparties, original, message, c...</td>\n",
       "      <td>-9.264912</td>\n",
       "      <td>zufferli-j</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94216 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Content  \\\n",
       "254576  ---------------------- Forwarded by Phillip K ...   \n",
       "254452  Naomi,\\n\\nThe two analysts that I have had con...   \n",
       "254553  ---------------------- Forwarded by Phillip K ...   \n",
       "254418  ---------------------- Forwarded by Phillip K ...   \n",
       "255431  Let me know when you get the quotes from Pauli...   \n",
       "...                                                   ...   \n",
       "48625   Can you re-activate the Alberta Power Pool Acc...   \n",
       "48443   \\n\\n-----Original Message-----\\nFrom: Lalani, ...   \n",
       "48522   Enron Canada Power Corp acknowledges the chang...   \n",
       "48586   Nella here is a list of products that we would...   \n",
       "48559   Here is a list of products and counterparties\\...   \n",
       "\n",
       "                       Date                     From  \\\n",
       "254576  2000-09-01 06:08:00  phillip.allen@enron.com   \n",
       "254452  1999-12-10 07:00:00  phillip.allen@enron.com   \n",
       "254553  2000-02-11 04:31:00  phillip.allen@enron.com   \n",
       "254418  2000-02-11 07:39:00  phillip.allen@enron.com   \n",
       "255431  2001-05-11 11:26:00  phillip.allen@enron.com   \n",
       "...                     ...                      ...   \n",
       "48625   2001-08-08 10:10:42  john.zufferli@enron.com   \n",
       "48443   2001-08-08 12:39:36  john.zufferli@enron.com   \n",
       "48522   2002-01-09 07:30:16  john.zufferli@enron.com   \n",
       "48586   2002-01-09 09:46:43  john.zufferli@enron.com   \n",
       "48559   2002-01-09 10:38:40  john.zufferli@enron.com   \n",
       "\n",
       "                                                   To  \\\n",
       "254576  mike.grigsby@enron.com, frank.ermis@enron.com   \n",
       "254452                       naomi.johnston@enron.com   \n",
       "254553                          keith.holst@enron.com   \n",
       "254418                         mike.grigsby@enron.com   \n",
       "255431                            jsmith@austintx.com   \n",
       "...                                               ...   \n",
       "48625                            help@enrononline.com   \n",
       "48443                         cooper.richey@enron.com   \n",
       "48522                    carol.moline@powerpool.ab.ca   \n",
       "48586                     nella.cappelletto@enron.com   \n",
       "48559                     nella.cappelletto@enron.com   \n",
       "\n",
       "                                                  Subject  \\\n",
       "254576                                                FYI   \n",
       "254452                                                NaN   \n",
       "254553                                 RE: W basis quotes   \n",
       "254418                          Western Strategy Briefing   \n",
       "255431                                                NaN   \n",
       "...                                                   ...   \n",
       "48625            Power Pool of Alberta EnronOnline Access   \n",
       "48443   FW: lavo_may_10 (slides 13-16)-revised (Aug 7,...   \n",
       "48522                                    Chevron Contract   \n",
       "48586                                            Products   \n",
       "48559                                        RE: Products   \n",
       "\n",
       "                                                   Tokens      VecSum  \\\n",
       "254576  [forward, phillip, allen, enron, north, americ...    7.766356   \n",
       "254452  [naomi, analyst, contact, lenhart, vishal, rep...  -14.676489   \n",
       "254553  [forward, phillip, allen, george, rahal, georg...   61.238914   \n",
       "254418  [forward, phillip, allen, heizenrader, james, ...   -8.750636   \n",
       "255431  [quote, pauline, expect, something, range, wou...   16.326239   \n",
       "...                                                   ...         ...   \n",
       "48625   [activate, alberta, power, access, enrononline...  177.460449   \n",
       "48443   [original, message, lalani, tuesday, august, z...   12.110354   \n",
       "48522   [enron, canada, power, acknowledge, change, as...   43.984802   \n",
       "48586   [nella, product, would, launch, netco, assume,...   -2.680151   \n",
       "48559   [product, counterparties, original, message, c...   -9.264912   \n",
       "\n",
       "            Origin  \n",
       "254576     allen-p  \n",
       "254452     allen-p  \n",
       "254553     allen-p  \n",
       "254418     allen-p  \n",
       "255431     allen-p  \n",
       "...            ...  \n",
       "48625   zufferli-j  \n",
       "48443   zufferli-j  \n",
       "48522   zufferli-j  \n",
       "48586   zufferli-j  \n",
       "48559   zufferli-j  \n",
       "\n",
       "[94216 rows x 8 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = []\n",
    "abs_start = start = time.time()\n",
    "for idx, user in enumerate(all_mails[\"X-Origin\"].unique()):\n",
    "    df = all_mails[all_mails[\"X-Origin\"]== user]\n",
    "    df = df[df[\"From\"].apply(lambda x:x in (mails_lookup[user]))]\n",
    "    df = df[[\"Content\", \"Date\", \"From\", \"To\", \"Subject\"]]\n",
    "    df[\"Origin\"] = [user for i in range(len(df))]\n",
    "    \n",
    "    tokens = list(df[\"Content\"].apply(tokenizer.tokenize))\n",
    "    tokens = [[token.lower() for token in tokenenized if len(token) > 4]\n",
    "              for tokenenized in tokens]\n",
    "    tokens = [[token for token in tokenenized if token not in stop_words]\n",
    "                    for tokenenized in tokens]\n",
    "    df[\"Tokens\"] = [[get_lemma(token) for token in tokenenized]\n",
    "                    for tokenenized in tokens]\n",
    "    \n",
    "    df.drop(df[df[\"Tokens\"].apply(lambda x: len(x) > 10000)].index, inplace=True)\n",
    "    \n",
    "    df[\"VecSum\"] = df[\"Tokens\"].apply(lambda x:\n",
    "        sum(vectorize(x)).sum() if type(sum(vectorize(x))) != int else sum(vectorize(x)))\n",
    "    \n",
    "    drop_idxs = []\n",
    "    for vec in df[\"VecSum\"].unique():\n",
    "        similar = df[df[\"VecSum\"] == vec]\n",
    "        for date in similar[\"Date\"].unique():\n",
    "            drop_idxs.extend(similar[similar[\"Date\"] == date].index[1:])\n",
    "    \n",
    "    df.drop(drop_idxs, inplace=True)\n",
    "    df[\"Origin\"] = [user for i in range(len(df))]\n",
    "    dfs.append(df); del(df)\n",
    "    \n",
    "    print(idx +1, \"/\", len(all_mails[\"X-Origin\"].unique()),\n",
    "          user, \"took\", round(time.time() -start, 2), \"seconds.\")\n",
    "    start = time.time()\n",
    "    \n",
    "sent_mails = pd.concat(dfs)\n",
    "print(\"Total time taken:\", round(time.time() -abs_start, 2)/60, \"minutes.\")\n",
    "\n",
    "del(dfs)\n",
    "sent_mails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_mails.to_csv(join(path, \"sent_mails.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionary & corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 0.85 seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "collection = []\n",
    "for idx in sent_mails.index:\n",
    "    collection.append(sent_mails.loc[idx, \"Tokens\"])\n",
    "    \n",
    "print(\"Took\", round(time.time()-start, 2), \"seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 12.51 seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "dictionary = corpora.Dictionary(collection)\n",
    "dictionary.save(join(path, \"sent_dictionary.gensim\"))\n",
    "\n",
    "print(\"Took\", round(time.time()-start, 2), \"seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155872 unique words in dictionary\n"
     ]
    }
   ],
   "source": [
    "print(len(dictionary.keys()), \"unique words in dictionary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 8.22 seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "corpus = [dictionary.doc2bow(tokens) for tokens in collection]\n",
    "pickle.dump(corpus, open(join(path, \"sent_corpus.pkl\"), \"wb\"))\n",
    "\n",
    "print(\"Took\", round(time.time()-start, 2), \"seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_mails[\"Corpus\"] = corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "reply_lst = [\"RE\",\"Re:\",\"re:\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7a2ff2a68284427a277f9252b5cf7c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Pandas Apply', max=94216.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sent_mails[\"Reply\"] = sent_mails[\"Subject\"].swifter.apply(\n",
    "    lambda x: any(map(lambda tag: tag in x, reply_lst))\n",
    "    if type(x) != float else False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_reverse = {v:k for k,v in dictionary.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_word_idxs = list(map(lambda x: dict_reverse[x], [\"forward\", \"forwarding\", \"dforward\",\"forwarde\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddd48fc50ada4230bf29fdcf05d1fc1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Pandas Apply', max=94216.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "forward_idxs = sent_mails[sent_mails[\"Corpus\"].swifter.apply(lambda x: any([\n",
    "        any(map(lambda pair: pair[0]==word, x))\n",
    "        for word in forward_word_idxs\n",
    "]))].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_mails[\"Forward\"] = [True if idx in forward_idxs else False for idx in sent_mails.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reordered and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_mails = sent_mails[\n",
    "    [\"Date\",\"Origin\",\"From\",\"To\",\"Subject\",\"Forward\",\"Reply\",\"Content\",\"Tokens\",\"Corpus\",\"VecSum\"]\n",
    "]; sent_mails.to_csv(join(path, \"sent_mails.csv\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
