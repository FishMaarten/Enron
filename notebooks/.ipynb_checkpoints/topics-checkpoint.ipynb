{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import email\n",
    "import pickle\n",
    "\n",
    "import os; \n",
    "from os import listdir\n",
    "from os.path import join, isdir\n",
    "\n",
    "import pandas as pd\n",
    "import swifter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "path = \"/media/becode/3D_House/Enron_CSV/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(join(path, \"reduced_mails_FINAL.csv\"), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lemma(word):\n",
    "    lemma = wordnet.morphy(word)\n",
    "    if lemma is None: return word\n",
    "    else: return lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparation(email):\n",
    "    tokens = tokenizer.tokenize(email)\n",
    "    tokens = [t for t in tokens if len(t) > 4]\n",
    "    tokens = [t for t in tokens if t not in stop_words]\n",
    "    tokens = [get_lemma(token) for token in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "714e90a847124bf890e0b53a7ab640c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Pandas Apply', max=288337.0, style=ProgressStyle(descriptâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data[\"Lemmet\"] = data[\"Content\"].swifter.apply(preparation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Length\"] = data[\"Lemmet\"].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32251612 words\n"
     ]
    }
   ],
   "source": [
    "collection = []\n",
    "for idx in data.index:\n",
    "    collection.append(data.loc[idx, \"Lemmet\"])\n",
    "\n",
    "print(sum(list(map(len, collection))), \"words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.save(join(path, \"dictionary.gensim\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary.load(join(path, \"dictionary.gensim\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500372 unique words in dictionary\n"
     ]
    }
   ],
   "source": [
    "print(len(dictionary.keys()), \"unique words in dictionary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(tokens) for tokens in collection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(corpus, open(join(path, \"corpus.pkl\"), \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pickle.load(open(join(path, \"corpus.pkl\"), \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Corpus\"] = corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_keys = [v[0] for v in dictionary.items() if \"orward\" in v[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Forwarded'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary[forward_keys[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Forwarded',\n",
       " 'Phillip',\n",
       " 'K',\n",
       " 'Allen',\n",
       " 'HOU',\n",
       " 'ECT',\n",
       " '09',\n",
       " '01',\n",
       " '2000',\n",
       " '01',\n",
       " '07',\n",
       " 'PM',\n",
       " 'Enron',\n",
       " 'North',\n",
       " 'America',\n",
       " 'Corp',\n",
       " 'From',\n",
       " 'Matt',\n",
       " 'Motley',\n",
       " '09',\n",
       " '01',\n",
       " '2000',\n",
       " '08',\n",
       " '53',\n",
       " 'AM',\n",
       " 'To',\n",
       " 'Phillip',\n",
       " 'K',\n",
       " 'Allen',\n",
       " 'HOU',\n",
       " 'ECT',\n",
       " 'ECT',\n",
       " 'cc',\n",
       " 'Subject',\n",
       " 'FYI',\n",
       " 'Ray',\n",
       " 'Niles',\n",
       " 'Price',\n",
       " 'Caps',\n",
       " 'pdf']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ast.literal_eval(data[\"Words\"].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ast' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-2444c1c692da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Words\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Words\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mliteral_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Took\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"seconds.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ast' is not defined"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "data[\"Words\"] = data[\"Words\"].apply(ast.literal_eval)\n",
    "\n",
    "print(\"Took\", round(time.time() -start), \"seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{word: data[\"Words\"].iloc[0].count(word) for word in data[\"Words\"].iloc[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "288337"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "288337"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = 10, id2word=dictionary, passes=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldamodel.save(join(path, \"model5.gensim\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.019*\"would\" + 0.011*\"going\" + 0.011*\"think\" + 0.008*\"could\" + 0.007*\"still\" + 0.007*\"people\" + 0.006*\"money\" + 0.005*\"want\" + 0.005*\"around\" + 0.005*\"today\"')\n",
      "(1, '0.044*\"IMAGE\" + 0.011*\"Click\" + 0.009*\"email\" + 0.007*\"click\" + 0.006*\"receive\" + 0.006*\"please\" + 0.006*\"Cannot\" + 0.006*\"online\" + 0.005*\"offer\" + 0.005*\"include\"')\n",
      "(2, '0.036*\"database\" + 0.028*\"dbCaps97Data\" + 0.019*\"London\" + 0.019*\"Alias\" + 0.018*\"Scheduled\" + 0.016*\"Outages\" + 0.012*\"close\" + 0.012*\"perform\" + 0.011*\"operation\" + 0.011*\"system\"')\n",
      "(3, '0.020*\"Enron\" + 0.011*\"company\" + 0.010*\"market\" + 0.008*\"power\" + 0.007*\"would\" + 0.007*\"energy\" + 0.006*\"price\" + 0.006*\"business\" + 0.005*\"state\" + 0.005*\"million\"')\n",
      "(4, '0.018*\"Enron\" + 0.012*\"schedule\" + 0.010*\"please\" + 0.009*\"information\" + 0.008*\"enron\" + 0.008*\"employee\" + 0.008*\"Please\" + 0.007*\"access\" + 0.007*\"HourAhead\" + 0.006*\"Portland\"')\n",
      "(5, '0.046*\"Subject\" + 0.041*\"Enron\" + 0.030*\"Original\" + 0.030*\"Message\" + 0.018*\"ENRON\" + 0.016*\"Thanks\" + 0.009*\"ENRON_DEVELOPMENT\" + 0.008*\"Tuesday\" + 0.008*\"David\" + 0.008*\"Please\"')\n",
      "(6, '0.017*\"Please\" + 0.015*\"please\" + 0.013*\"Thanks\" + 0.012*\"information\" + 0.011*\"question\" + 0.011*\"change\" + 0.010*\"attach\" + 0.009*\"would\" + 0.009*\"review\" + 0.009*\"enron\"')\n",
      "(7, '0.032*\"Energy\" + 0.030*\"Power\" + 0.015*\"price\" + 0.011*\"Market\" + 0.010*\"trade\" + 0.009*\"product\" + 0.009*\"Price\" + 0.008*\"Natural\" + 0.007*\"Schedules\" + 0.007*\"Financial\"')\n",
      "(8, '0.030*\"width\" + 0.027*\"class\" + 0.019*\"script\" + 0.019*\"image\" + 0.017*\"align\" + 0.016*\"height\" + 0.016*\"border\" + 0.015*\"Arial\" + 0.015*\"Updated\" + 0.014*\"color\"')\n",
      "(9, '0.046*\"enron\" + 0.037*\"mailto\" + 0.030*\"Subject\" + 0.029*\"intend\" + 0.027*\"Message\" + 0.026*\"recipient\" + 0.025*\"Original\" + 0.021*\"Unknown\" + 0.017*\"message\" + 0.014*\"ENRON\"')\n"
     ]
    }
   ],
   "source": [
    "topics = ldamodel.print_topics(num_words=10)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topics_from_employee():\n",
    "    df = reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "phillip.allen@enron.com                            615\n",
       "k..allen@enron.com                                 297\n",
       "arsystem@mailman.enron.com                          37\n",
       "no.address@enron.com                                30\n",
       "webmaster@earnings.com                              23\n",
       "                                                  ... \n",
       "editor@hersweeps.com                                 1\n",
       "networkcommerce-tdcd20011221@ombramarketing.com      1\n",
       "software@mail02.unitedmarketingstrategies.com        1\n",
       "brad.jones@enron.com                                 1\n",
       "mark.whitt@enron.com                                 1\n",
       "Name: From, Length: 182, dtype: int64"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data[\"Author\"]==\"allen-p\"][\"From\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mails = pd.read_csv(join(path, \"all_mails.csv\"), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "phillip.allen@enron.com           2125\n",
       "k..allen@enron.com                 297\n",
       "arsystem@mailman.enron.com          39\n",
       "no.address@enron.com                30\n",
       "webmaster@earnings.com              27\n",
       "                                  ... \n",
       "c..aucoin@enron.com                  1\n",
       "lisa@techxans.org                    1\n",
       "ksumey@ftenergy.com                  1\n",
       "prizemachine@feedback.iwon.com       1\n",
       "infousa4492@telkom.net               1\n",
       "Name: From, Length: 182, dtype: int64"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_mails[all_mails[\"X-Origin\"]==\"allen-p\"][\"From\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## need to re-reduce the all_mails set to include every sent mail from employ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee = pd.read_csv(join(path, \"employees.csv\"), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Last</th>\n",
       "      <th>First</th>\n",
       "      <th>Mail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Allen</td>\n",
       "      <td>Phillip</td>\n",
       "      <td>['phillip.allen@enron.com', 'k..allen@enron.com']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>Love</td>\n",
       "      <td>Phillip</td>\n",
       "      <td>['m..love@enron.com', 'phillip.love@enron.com']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>Platter</td>\n",
       "      <td>Phillip</td>\n",
       "      <td>['phillip.platter@enron.com']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Last    First                                               Mail\n",
       "5      Allen  Phillip  ['phillip.allen@enron.com', 'k..allen@enron.com']\n",
       "114     Love  Phillip    ['m..love@enron.com', 'phillip.love@enron.com']\n",
       "143  Platter  Phillip                      ['phillip.platter@enron.com']"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "employee[employee[\"First\"]==\"Phillip\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "allen = all_mails[all_mails[\"From\"].apply(lambda x: x in employee.loc[5, \"Mail\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct = {}\n",
    "for origin in sorted(all_mails[\"X-Origin\"].unique()):\n",
    "    dct[origin] = all_mails[all_mails[\"X-Origin\"]==origin][\"From\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(list(map(lambda x: \"allen\" in x, list(dct[\"allen-p\"].keys()))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
